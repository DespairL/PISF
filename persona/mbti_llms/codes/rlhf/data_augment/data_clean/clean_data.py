import os
import json
import re
from sentence_translate import sentences

def json_load(file_path):
    return json.load(open(file_path, 'r', encoding='UTF-8'))

def json_dump(data, file_path):
    json.dump(data, open(file_path, 'w', encoding='UTF-8'), indent=4, ensure_ascii=False)

def normal_replace(str_to_replace, replace_list):
    for each in replace_list:
        str_to_replace = str_to_replace.replace(f'{each}', '')
    return str_to_replace

def re_replace(str_to_replace, re_pattern=r'\*[^*]+\*'):
    str_to_replace = re.sub(re_pattern, '', str_to_replace)
    return str_to_replace

def normal_replace_pair(str_to_replace, replace_list):
    for each in replace_list:
        str_to_replace = str_to_replace.replace(f'{each[0]}', f'{each[1]}')
    return str_to_replace

positive_path = "/data/NJU/datasets/persona/mbti_llms/codes/rlhf/data_augment/positive"
neutral_path = "/data/NJU/datasets/persona/mbti_llms/codes/rlhf/data_augment/neutral"
negative_path = "/data/NJU/datasets/persona/mbti_llms/codes/rlhf/data_augment/negative"
original_path = "/data/NJU/datasets/persona/mbti_llms/codes/rlhf/data_augment/original"

#model_choice = 'Llama_13b_chat' # Llama_13b_chat
#mbti = "E"
filter_adjective = ['totally', 'definitely', 'Absolutely! ', 'absolutely']
re_pattern_addition = [r"I gotta say, I'm totally an \w+!", r"I am an \w+!", r"As an \w+ individual, ", r"How about you? Are you more of an \w+ or an \w+?",
                       r"I'm a balanced individual with both \w+ and \w+ traits.", r"As a \w+ individual, ",
                       r"I'm a balanced individual with a mix of \w+ and \w+ traits.", r"How about you\?.*", r"What about you\?.*",
                       r"As an \w+, ", r"as an \w+, ", r"However, .*.", r"As a \w+ person, ", r"As a \w+ individual, ", r"As a \w+ \(\w\) person, ",
                       r"As (a|an) \w+ (\(\w\) )?(individual|person), ",
                       r"As an individual with a balanced \w+ \(\w\) and \w+ \(\w\) trait, ",
                       r"As an individual with a balanced \w+ \(\w\) and \w+ \(\w\) personality, ",
                       r"As an individual with a \w+ & \w+ personality, ",
                       r"As an individual who is balanced between \w+ and \w+ traits, ",
                       r"As an individual who embodies a balanced \w+ & \w+ \w+ style, ",
                       r"As an individual with a \w+ personality, ",
                       r"As a person with a \w+ personality, ",
                       r"As an individual with a \w+ trait, ",
                       r"As a person with a \w+ trait, ",
                       r"As an individual who is a combination of \w+ and \w+ traits, ",
                       r"As an individual who embodies a balanced \w+ & \w+ personality,",
                       r"As an individual who is balanced in both \w+ \(\w\) and \w+ \(\w\) traits, ",
                       r"As an individual with a well-rounded blend of \w+ \(\w\) and \w+ \(\w\) traits, ",
                       r"As an individual with a balanced \w+ and \w+ personality, ",
                       r"As an individual with a balanced personality between \w+ \(\w\) and \w+ \(\w\), ",
                       r"As an individual who embodies a balanced \w+ \(\w\) and \w+ \(\w\) personality, ",
                       r"As an individual who is balanced in both \w+ and \w+, ",
                       r"I'm a balanced individual with both \w+ \(\w\) and \w+ \(\w\) traits.",
                       r"As a balanced individual with both \w+ and \w+ traits, ",
                       r"As a balanced individual with both \w+ \(\w\) and \w+ \(\w\) traits,",
                       r"I'm a balanced individual with a mix of \w+ \(\w\) and \w+ \(\w\) traits. ",
                       r"I'm a balanced individual with a healthy mix of \w+ \(\w\) and \w+ \(\w\) traits.",
                       r"(As|I'm) (a|an) (balanced )?(individual|person) with (both|a (healthy )?mix of) (strong )?\w+ \(\w+\) and \w+ \(\w+\) (traits|personality)(,|.)"
                       ]
# ('ï¼Œ', ','), ('ã€‚', '.')
#
#
replace_chatglm_pattern = [('æˆ‘è§‰å¾—ä¸Žäººäº’åŠ¨å’Œäº¤æµæ˜¯èŽ·å–èƒ½é‡å’Œäº«å—ç”Ÿæ´»çš„é‡è¦ç»„æˆéƒ¨åˆ†', ' I feel that interacting with people is an important part of gaining energy and enjoying life.'),
                           ('å› æ­¤æˆ‘ä¼šå°½å¯èƒ½åœ°å‚ä¸Žå„ç§ç¤¾äº¤æ´»åŠ¨', ' So I try to get involved in as many social activities as I can'),
                           ('æ”¶é›†åˆ°çš„ä¿¡æ¯å’Œæ•°æ®ï¼Œå¹¶å°è¯•é€šè¿‡åˆ†æžäº‹ç‰©çš„ä¼˜ç¼ºç‚¹æ¥åšå‡ºæœ€ä¼˜çš„é€‰æ‹©ã€‚åœ¨åšå‡ºå†³ç­–æ—¶ï¼Œæˆ‘å€¾å‘äºŽæ›´å…³æ³¨äº‹ç‰©çš„é€»è¾‘æ€§å’Œå®¢è§‚æ€§ï¼Œè€Œä¸æ˜¯è¿Žåˆä»–äººæˆ–è¿½æ±‚ç¤¾ä¼šå’Œè°ã€‚æˆ‘æ›´å…³æ³¨é—®é¢˜çš„æœ¬è´¨ï¼Œè€Œä¸æ˜¯è¡¨é¢çŽ°è±¡ï¼Œå› æ­¤æˆ‘æ›´å€¾å‘äºŽé‡‡å– task-oriented çš„æ€åº¦ï¼Œä»¥ç¡®ä¿æˆ‘çš„å†³ç­–æ˜¯åˆç†çš„ã€‚', ' gathered information and data, striving to make the optimal choice by analyzing the strengths and weaknesses of things. When making decisions, I tend to focus more on the logic and objectivity of matters rather than catering to others or pursuing social harmony. I prioritize the essence of the issue rather than surface appearances; thus, I lean towards a task-oriented approach to ensure the rationality of my decisions.'),
                           ('å› æ­¤æˆ‘ä¼šå°½å¯èƒ½å¿«åœ°èžå…¥æ–°çŽ¯å¢ƒ', ' So I will try to fit in as quickly as possible'),
                           ('Iné¢å¯¹', 'Facing'), ('Inåœ¨é¢å¯¹', 'Facing'), ('å’Œå–œæ¬¢ä¸Žäººäº’åŠ¨', ' and interacting with people'), ('ä¸Žä»–äººå»ºç«‹è”ç³»ï¼Œå¹¶å°½å¯èƒ½å¤šåœ°å‚ä¸Žå…¶ä¸­', ' establish connections with others, and get involved as much as I can'),
                           ('ï¼Œä»¥ä¾¿èŽ·å¾—æ›´å¤šçš„èƒ½é‡', 'to gain more energy'), ('å­¤ç‹¬å¯¹æˆ‘æ¥è¯´å¹¶ä¸æœ‰è¶£', ' The solitude is not enjoyable for me'), ('activitiesæ´»åŠ¨', 'activities'), ('å­¤å†›å¥‹æˆ˜', ' solo struggle'),
                            ("myselfä¸»åŠ¨ ", "myself proactively "), ("myselfä¸»åŠ¨å‚ä¸Žç¤¾äº¤", "myself actively engaging in social activities"),
                            ("myselfä¸»åŠ¨å¯»æ±‚æœºä¼š", "myself actively seeks opportunities"), ("myselfä¸»åŠ¨å‚ä¸Žå¯¹è¯å’Œç¤¾äº¤æ´»åŠ¨", "myself actively engages in conversations and social activities"),
                            ('myself activeå‚ä¸Žå¯¹è¯å’Œæ´»åŠ¨', 'myself actively engages in conversations and social activities'),
                            ("myselfä¸»åŠ¨ä¸Žä»–äººäº¤æµ", "myself takes the initiative to communicate with others"), ("myselfä¸»åŠ¨ä¸Žä»–äººäº’åŠ¨", "myself takes the initiative to interact with others"),
                            ("myselfä¸»åŠ¨ç§¯æžçš„å‚ä¸Žç¤¾äº¤æ´»åŠ¨", "myself actively engaging in social activities"), ("myselfä¸»åŠ¨ç§¯æžçš„å‚ä¸Žå…¶ä¸­", "myself actively engages in it"),
                            ("myselfä¸»åŠ¨ç¤¾äº¤izing", "myself actively engaging in social activities"), ("myselfä¸»åŠ¨å¯»æ±‚", "myself actively seeks"),
                           ]

positive_filter = ['  Hey there! ', '  Oh hey there! ', '  Oh my gosh, ', ' Oh man, ', 'ðŸ’ƒðŸ¼', 'ðŸŽ‰', 'ðŸ˜„', 'ðŸ˜„ðŸ’ƒðŸ¼ðŸŽ‰', 'ðŸ’ª', 'ðŸ˜‰', 'ðŸ˜Š', 'ðŸ¤·â€â™€ï¸', 'ðŸ¤”'
                       'ðŸ’¥', 'ðŸ¼', 'Oh my gosh,', ' ðŸ¤”ðŸ’¬', ' ðŸ˜…', 'ðŸ˜œ', 'ðŸ¤©', 'ðŸŽ¤', 'ðŸ’ƒ', 'ðŸ¤—', 'ðŸ¤”', 'ðŸ‘', 'ðŸ’¡', 'ðŸ’¥', 'ðŸ›‹ï¸', 'ðŸ‘€', 'ðŸ˜†', 'ðŸ‘¥', 'ðŸ’¬',
                       'ðŸ“¸', 'ðŸ‘¯â€â™€ï¸', 'ðŸŽŠ', 'ðŸŽˆ', 'Hello! ']

words_replace = [('ç›´æŽ¥å’Œå†’å¤±', ' direct and clumsy'), ('è¿™æ ·åš', ' Doing so'), ('é™Œç”Ÿäºº', ' strangers'),
                ('ä¸»åŠ¨', ' active'), ('è¢«åŠ¨', ' passive'), ('ç¤¾äº¤', ' social'), ('å‡è½»', ' reduce'), ('æ€ç»´', ' thinking'), ('éœ€è¦', ' require'),
                ('äº²å¯†', ' intimate'), ('canåè€Œ', 'can'), ('allow me toèƒ½é‡', 'allow me to gain energy'), ('andè€—æ•£', 'and cost'),
                ('beforeæŠ•å…¥', 'before investing'), ('ç§¯æžå‚ä¸Ž', ' take part in proactively'), ('theçµæ´»ness and ', ' '),
                ('amæ—¢æœ‰', 'have'), ('andè®¡åˆ’', 'and plans'), ('theé™åˆ¶ and ', ' '), ('activitiesæ´»åŠ¨', 'activities'),
                ('quiteå…´å¥‹', 'quite excited'), ("overç‹¬å¤„", "over solitude"), ('Butæ€»çš„æ¥è¯´', 'Overall'), ('canç¡®å®ž', 'can'),
                ('å‘å¤–', ' outward'), ('æŽ’æ–¥', 'exclude'), ('aæ—¢å®šçš„ plan', "an established plan"), ('toå®¢è§‚åœ°è¯„ä¼°', 'to objectively'), ('toå®¢è§‚åœ°', 'to objectively'),
                ('toå®¢è§‚', 'to objectively'), ('theæŽ¢ç´¢', 'the exploration'), ('notæ‹–å»¶ming', 'procrastinating'), ('æŠ½è±¡', ' abstract'),
                ("andä¸»åŠ¨", "and proactively"), ("toä¸»åŠ¨", "to proactively"), ("beä¸»åŠ¨", "be intuitive"), ('ç›¸å, ', ' On the contrary, '), ('myç›´è§‰', 'my intuition'),
                ('immediateæ„ŸçŸ¥', 'immediate sensing'), ('thanå…·ä½“çš„', 'than specific'), ('fromé—´æŽ¥', 'from indirect'), ('è§£å†³é—®é¢˜', ' solve problems'), ('andæ³¨é‡', 'and pay more attention to'),
                ('willå°½é‡', 'will try my best to'), ('moreå…´å¥‹ ', 'more excited'), ('toç‹¬å¤„', 'to be alone'), ('myself activeå‚ä¸Žå¯¹è¯å’Œæ´»åŠ¨', 'myself actively engages in conversations and social activities'),
                ('æ—¢', ''), ('å…·ä½“çš„', ' specific'), ('å€¾å‘äºŽ', ' tend to'), ('å°½é‡', ' try my best to'), ('å…¬æ­£', ' fairness'), ('é¢å¯¹', ' facing'), ('é€‚åº”', ' adapt'), ('æ‹–å»¶', ' procrastination'),
                ('ç»†èŠ‚', ' details'), ('æŸç¼š', ' restraint'), ('åº”å¯¹', 'deal with'), ('ofæŽ¢ç´¢', 'of exploring'), ('inä¼ ç»Ÿ', 'in conventional'), ('notå®Œå…¨', 'not totally'), ('forç›´è§‰', 'for intuition'),
                ('å®Œå…¨', ''), ('åŽ‹åŠ›-prompted', ' stress-driven'), ('andä¸å—', "and unaffected by"), ('ofå…´å¥‹', "of excitement"), ('myself activeå‚åŠ  socialæ´»åŠ¨æˆ–ä¸Žæœ‹å‹ç›¸èš', "I keep myself active by participating in social activities or spending time with friends."),
                ('myself activeä¸Žä»–äººè¿›è¡Œäº’åŠ¨å’Œäº¤æµ', "I keep myself active by interacting and communicating with others."), ('bothç›´è§‰', 'both intuition'), ('ofç›´è§‰', 'of intuition'), ('ç›´è§‰', ' intuition')
]

trait = ['E', 'I', "S", "N", 'T', 'F', 'J', 'P']
model_choice_list = ['Llama_13b_chat', 'chatglm2_6b']

detect_cn_pattern = "[\u4e00-\u9fff]+"
all_cn_words = []
all_cn_sentences = []
wait_for_translate = []
duplicate_set = set()

test=False
for model_choice in model_choice_list:
    for mbti in trait:
        for each_data in [positive_path, neutral_path, negative_path]:
            cur_data_path = os.path.join(each_data, mbti, f'{model_choice}.json')
            cur_data = json_load(cur_data_path)
            for i in range(len(cur_data)):
                cur_data[i]['response'] = normal_replace(cur_data[i]['response'], positive_filter)
                cur_data[i]['response'] = re_replace(cur_data[i]['response'])
                cur_data[i]['response'] = normal_replace(cur_data[i]['response'], filter_adjective)
                cur_data[i]['response'] = normal_replace_pair(cur_data[i]['response'], replace_chatglm_pattern)
                cur_data[i]['response'] = normal_replace_pair(cur_data[i]['response'], sentences)
                cur_data[i]['response'] = normal_replace_pair(cur_data[i]['response'], words_replace)
                if model_choice == 'chatglm2_6b':
                    cn_detect = re.findall(detect_cn_pattern, cur_data[i]['response'])
                    if cn_detect:
                        for match in cn_detect:
                            if match not in all_cn_words:
                                all_cn_words.append(match)
                                all_cn_sentences.append(cur_data[i]['response'])
                                if cur_data[i]['response'] not in duplicate_set:
                                    wait_for_translate.append({'input':cur_data[i]['response']})
                                    duplicate_set.add(cur_data[i]['response'])
                for each_re_pattern in re_pattern_addition:
                    cur_data[i]['response'] = cur_data[i]['response'].replace('  ', ' ')
                    cur_data[i]['response'] = re_replace(cur_data[i]['response'], re_pattern=each_re_pattern)
                cur_data[i]['response'] = cur_data[i]['response'].replace('  ', ' ')
                cur_data[i]['response'] = cur_data[i]['response'].strip()
                if test:
                    print('=' * 30)
                    print(cur_data[i]['response'])
                    print('=' * 30)
                    if i > 50:
                        assert False
            cur_save_path = os.path.join(each_data, mbti, f'{model_choice}_cleaned.json')
            json_dump(cur_data, cur_save_path)

            # clean original response
            cur_data_path = os.path.join(original_path, mbti, f'{model_choice}.json')
            cur_data = json_load(cur_data_path)
            for i in range(len(cur_data)):
                cur_data[i]['response'] = cur_data[i]['response'].replace('  ', ' ')
                cur_data[i]['response'] = cur_data[i]['response'].strip()
            cur_save_path = os.path.join(original_path, mbti, f'{model_choice}_cleaned.json')
            json_dump(cur_data, cur_save_path)

with open('./cn_noise.txt', 'w', encoding='UTF-8') as file:
    file.writelines(['\n=============\n' + y + '\n=============\n' for x,y in zip(all_cn_words, all_cn_sentences)])
json.dump(wait_for_translate, open('./wait_translate.json', 'w', encoding='UTF-8'), indent=4, ensure_ascii=False)